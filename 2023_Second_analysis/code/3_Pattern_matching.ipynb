{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71e8f5f",
   "metadata": {},
   "source": [
    "# Pattern matching\n",
    "\n",
    "\n",
    "We will start in the same way as the last notebook started  - by downloading/importing the packages needed and importing the .csv file(s) needed. In this case, we only need the .csv file that has the matched abstracts as we are specifically looking at person-first and identity-first patterns that are \"about\" autism (or ASD, Asperger's syndrome, etc.). \n",
    "\n",
    "We could use the same basic approach to look at person-first and identity-first language for other conditions for which there are good noun and adjective forms of the words (diabetes? obesity? cancer? something else?). Doing that would mean using the .csv file with all of the abstracts or potentially creating and entirely new file of abstracts matched to another condition of interest. However, that lies outside the scope of this research, so I will not address it further here. \n",
    "\n",
    "## Get ready \n",
    "\n",
    "As always, we start with a couple of code cells that load up and nickname some useful packages, then check file locations, then import files and check them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26078126",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# installing necessary pdf conversion packages via pip\n",
    "# the '%%capture' at the top of this cell suppresses the output (which is normally quite long and annoying looking). \n",
    "# You can remove or comment it out if you prefer to see the output. \n",
    "!pip install nltk\n",
    "!pip install spacy -q\n",
    "!python -m spacy download en_core_web_lg -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "271c801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import nltk                       # nltk stands for natural language tool kit and is useful for text-mining. \n",
    "from nltk import word_tokenize    # and some of its key functions\n",
    "from nltk import sent_tokenize  \n",
    "tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet                    # Finally, things we need for lemmatising!\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "nltk.download('averaged_perceptron_tagger')        # Like a POS-tagger...\n",
    "nltk.download('wordnet')\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import webtext\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "#import codecs\n",
    "import csv                        # csv is for importing and working with csv files\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import statistics\n",
    "import re                         # things we need for RegEx corrections\n",
    "import string \n",
    "import spacy \n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from spacy import displacy \n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 1500000 #or any large value, as long as you don't run out of RAM\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4677f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_count.jpg', 'all_abstracts_no_null_texts.csv', 'matched_abstracts_no_null_texts.csv', 'most_frequent_comparison.csv', 'text_match_results.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"..\\\\output\")  )      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e4ea5",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "Having checked the contents of the output folder and seen the files we expected to see, we can now import the specific file of interest for this step of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b74ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_texts = pd.read_csv('..\\\\output\\\\matched_abstracts_no_null_texts.csv')    # one for just those that match the keyword\n",
    "len(matched_texts)                                                                # check the length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d89f25",
   "metadata": {},
   "source": [
    "## Cleaning phase\n",
    "\n",
    "The first step of pattern matching is to prepare the data by sentence tokenising the text. Like word tokens, sentence tokens become the unit for analysisis. As a trivial example, sentence tokenisation would turn a short text such as \n",
    "\n",
    "\n",
    "''' The cat named Cat is one of five cats. Honestly, I wonder why I have so many cats.\n",
    "''' \n",
    "\n",
    "into a list of sentence tokens like\n",
    "\n",
    "''' [[The cat named Cat is one of five cats.]\n",
    "\n",
    "[Honestly, I wonder why I have so many cats.]]\n",
    "\n",
    "''' \n",
    "\n",
    "An important difference is that the punctuation within the sentences that contributes to its structured and meaning (e.g. the comma and the full stops) are retained. This punctuation, like the capitalisation at the start of the sentences or for the poper nouns, is also retained as it helps the sentence-tokenisation process identify the words within the sentence correctly for their parts of speech (e.g. which of the words are nouns, verbs, etc. ). \n",
    "\n",
    "\n",
    "\n",
    "The sentence tokens are then put on individual rows, filtered to retain only those that contain one or more of the keywords of interest, and then filtered to ensure that there are no empty rows or duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17421e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13444"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences  = [sent_tokenize(abstract) for abstract in matched_texts['Text'] ] # tokenize the text column and store as a list\n",
    "matched_texts['Sentence'] = sentences                                   # copy that list back into df as a new column\n",
    "sentence_per_row = matched_texts.explode('Sentence')                    # explode column in new df with 1 row/sentence token\n",
    "len(sentence_per_row)                                                   # check the length of new df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f59868f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Session_Code</th>\n",
       "      <th>Authors_and_Affiliations</th>\n",
       "      <th>Text</th>\n",
       "      <th>Year</th>\n",
       "      <th>Email</th>\n",
       "      <th>Author</th>\n",
       "      <th>Affiliations</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Genetic defects in sterol metabolism</td>\n",
       "      <td>S60.</td>\n",
       "      <td>F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Fabian.Moebius@uibk.ac.at</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Genetic defects in sterol metabolism</td>\n",
       "      <td>S60.</td>\n",
       "      <td>F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Fabian.Moebius@uibk.ac.at</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  the shift of the double bond from C8 9to C7 8(3ÃÂ§ sterol D 8 D7isomerase/EBP  E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Genetic defects in sterol metabolism</td>\n",
       "      <td>S60.</td>\n",
       "      <td>F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Fabian.Moebius@uibk.ac.at</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3.3.5) and the removal of the double bond at C7 8(D7 sterol reduc  tase/DHCR7  E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Genetic defects in sterol metabolism</td>\n",
       "      <td>S60.</td>\n",
       "      <td>F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Fabian.Moebius@uibk.ac.at</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3.1.21).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Genetic defects in sterol metabolism</td>\n",
       "      <td>S60.</td>\n",
       "      <td>F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M</td>\n",
       "      <td>Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Fabian.Moebius@uibk.ac.at</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missense and nonsense mutations in NSHDL on Xq28 cause X chromosomal dominant CHILD syndrome (congenitalhemidysplasia with ichthyosiform erythroderma and limb defects MIM308050)  a rare inborn dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This duplication  patients 49 returned with completed metabolic work up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this group  leads to an expansion of a polyalanine tract in the ARX protein.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>of 49 patients 18 had a diagnosis of autism and 31 of PDD, only one  The ARX gene was screened for mutations in Üve males with mental  patient was female, average age was 5.4 years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sixty percent of the  retardation associated with West syndrome and/or dystonia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The  patients had elevated lactate levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13444 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                 Title Session_Code  \\\n",
       "0            59  Genetic defects in sterol metabolism         S60.   \n",
       "0            59  Genetic defects in sterol metabolism         S60.   \n",
       "0            59  Genetic defects in sterol metabolism         S60.   \n",
       "0            59  Genetic defects in sterol metabolism         S60.   \n",
       "0            59  Genetic defects in sterol metabolism         S60.   \n",
       "..          ...                                   ...          ...   \n",
       "905        2158                                   NaN          NaN   \n",
       "905        2158                                   NaN          NaN   \n",
       "905        2158                                   NaN          NaN   \n",
       "905        2158                                   NaN          NaN   \n",
       "905        2158                                   NaN          NaN   \n",
       "\n",
       "                                                                                  Authors_and_Affiliations  \\\n",
       "0     F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M   \n",
       "0     F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M   \n",
       "0     F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M   \n",
       "0     F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M   \n",
       "0     F. MoebiusInstitute for Biochemical Pharmacology  University of Innsbruck  Innsbruck AustriaFabian.M   \n",
       "..                                                                                                     ...   \n",
       "905                                                                                                    NaN   \n",
       "905                                                                                                    NaN   \n",
       "905                                                                                                    NaN   \n",
       "905                                                                                                    NaN   \n",
       "905                                                                                                    NaN   \n",
       "\n",
       "                                                                                                                                                                                                        Text  \\\n",
       "0    Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...   \n",
       "0    Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...   \n",
       "0    Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...   \n",
       "0    Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...   \n",
       "0    Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes. They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  th...   \n",
       "..                                                                                                                                                                                                       ...   \n",
       "905  P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...   \n",
       "905  P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...   \n",
       "905  P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...   \n",
       "905  P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...   \n",
       "905  P0833Screening for ARX gene mutations is indicated for males  problems. The study of this disorder has intensiÜed because  with mental retardation associated with West syndrome and/or  incidence i...   \n",
       "\n",
       "       Year                      Email Author Affiliations  \\\n",
       "0    2001.0  Fabian.Moebius@uibk.ac.at    NaN          NaN   \n",
       "0    2001.0  Fabian.Moebius@uibk.ac.at    NaN          NaN   \n",
       "0    2001.0  Fabian.Moebius@uibk.ac.at    NaN          NaN   \n",
       "0    2001.0  Fabian.Moebius@uibk.ac.at    NaN          NaN   \n",
       "0    2001.0  Fabian.Moebius@uibk.ac.at    NaN          NaN   \n",
       "..      ...                        ...    ...          ...   \n",
       "905  2004.0                        NaN    NaN          NaN   \n",
       "905  2004.0                        NaN    NaN          NaN   \n",
       "905  2004.0                        NaN    NaN          NaN   \n",
       "905  2004.0                        NaN    NaN          NaN   \n",
       "905  2004.0                        NaN    NaN          NaN   \n",
       "\n",
       "                                                                                                                                                                                                    Sentence  \n",
       "0                                                                                     Genetic defects in sterol metabolizing enzymes have recently emerged asimportant causes of dysmorphogenetic syndromes.  \n",
       "0                                            They affect enzymesrequired for the removal of methyl groups at C4(NSHDL)  the shift of the double bond from C8 9to C7 8(3ÃÂ§ sterol D 8 D7isomerase/EBP  E.C.  \n",
       "0                                                                                                                      5.3.3.5) and the removal of the double bond at C7 8(D7 sterol reduc  tase/DHCR7  E.C.  \n",
       "0                                                                                                                                                                                                 1.3.1.21).  \n",
       "0    Missense and nonsense mutations in NSHDL on Xq28 cause X chromosomal dominant CHILD syndrome (congenitalhemidysplasia with ichthyosiform erythroderma and limb defects MIM308050)  a rare inborn dis...  \n",
       "..                                                                                                                                                                                                       ...  \n",
       "905                                                                                                                                 This duplication  patients 49 returned with completed metabolic work up.  \n",
       "905                                                                                                                          In this group  leads to an expansion of a polyalanine tract in the ARX protein.  \n",
       "905                    of 49 patients 18 had a diagnosis of autism and 31 of PDD, only one  The ARX gene was screened for mutations in Üve males with mental  patient was female, average age was 5.4 years.  \n",
       "905                                                                                                                         Sixty percent of the  retardation associated with West syndrome and/or dystonia.  \n",
       "905                                                                                                                                                                The  patients had elevated lactate levels  \n",
       "\n",
       "[13444 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_per_row                                                    # have a look. For the first two rows, \n",
    "                                                                    # 'Text' should be same, but 'Sentence' should not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3795c76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sentences = sentence_per_row[sentence_per_row['Sentence'].str.contains('autis|Autis|ASD|Asperger|asperger')]\n",
    "                                                     # create a new data frame with only the sentences that contain keywords\n",
    "len(matched_sentences)                               # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8cdb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sentences = matched_sentences[~matched_sentences['Sentence'].isnull()]  # remove any rows with empty 'Sentence' column\n",
    "matched_sentences = matched_sentences.drop_duplicates()                         # drop any duplicates\n",
    "len(matched_sentences)                                                          # check length of remaining data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0de07",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Following the cleaning phase, we move on to the extraction phase. This has two parts, first for the person-first extraction and then for the identity-first extraction. \n",
    "\n",
    "The results of both extractions are saved in their own column to make it easy to read and also to allow for a single sentence-token to contain both kinds of patterns. \n",
    "\n",
    "### Person-first pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d739a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_2 = [{\"POS\": \"NOUN\"},                                                   # define the person-first pattern(s)\n",
    "             {'LOWER': 'with'},                                                 # I made 3 for clarity rather than one with \n",
    "             {'DEP':'amod', 'OP':\"?\"},                                          # a real complex regex string\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"TEXT\": {\"REGEX\": \"^[Aa]utism$\"}}]\n",
    "\n",
    "pattern_3 = [{\"POS\": \"NOUN\"},\n",
    "             {'LOWER': 'with'},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"TEXT\": {\"REGEX\": \"^[Aa]sperger$\"}}]\n",
    "\n",
    "pattern_4 = [{\"POS\": \"NOUN\"},\n",
    "             {'LOWER': 'with'},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"TEXT\": {\"REGEX\": \"^ASD$\"}}]\n",
    "\n",
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab)                                                  # define a matcher class object\n",
    "matcher.add(\"matching_1\", [pattern_2, pattern_3, pattern_4])                  # add my three person-first patterns to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_match(input):                                               # define a function that applies the person-first\n",
    "    thingy = nlp(input)                                                       # matcher class object to strings\n",
    "    match = matcher(thingy)                                                   # and returns any matches to the pattern(s)\n",
    "    if match == []:\n",
    "        out_value = ''\n",
    "    else:\n",
    "        hold_multi_spans = []\n",
    "        for match_id, start, end in match:\n",
    "                string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "                span = thingy[start:end]  # The matched span\n",
    "                hold_multi_spans.append(span)\n",
    "        out_value = hold_multi_spans\n",
    "    return out_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffd7373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sentences['Person-first'] = matched_sentences.apply(lambda row: find_pattern_match(row.Sentence), axis = 1)\n",
    "                                                                        # apply the newly defined person-first matcher function\n",
    "                                                                        # and store the returned output in a new column\n",
    "len(matched_sentences)                                                  # double check length remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cc982",
   "metadata": {},
   "source": [
    "### Identity-first pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc18f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_a = [{\"TEXT\": {\"REGEX\": \"^[Aa]utistic\"}},                        # do the same for identity-first patterns\n",
    "             {'DEP':'amod', 'OP':\"?\"},                                   # again, i wrote 3 patterns for clarity sake\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"POS\": \"NOUN\"}]\n",
    "\n",
    "pattern_b = [{\"TEXT\": {\"REGEX\": \"^[Aa]sperger\"}},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"POS\": \"NOUN\"}]\n",
    "\n",
    "pattern_c = [{\"TEXT\": {\"REGEX\": \"^ASD\"}},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"POS\": \"NOUN\"}]\n",
    "\n",
    "# Matcher class object                                         \n",
    "matcher = Matcher(nlp.vocab) \n",
    "matcher.add(\"matching_2\", [pattern_a, pattern_b, pattern_c])            # this overwrites the matcher object to identity-first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences['Identity-first'] = matched_sentences.apply(lambda row: find_pattern_match(row.Sentence), axis = 1)\n",
    "                                                                        # apply the newly overwritten matcher function\n",
    "                                                                        # and store the returned output in a new column\n",
    "len(matched_sentences)                                                  # check the length - why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406db79a",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "\n",
    "Following the cleaning and extraction phases, the last phase is consolidation. This phase further refines the data by removing all the rows that do not contain a match for one or both of the patterns. For example, there would be a row for \"The child was tested for autism.\" because it contains a keyword of interest. However, this sentence would be eliminated in the consolidation phase as the keyword does not fit into either the person-first or identity-first patterns. \n",
    "\n",
    "Further, this phase goes on to lemmatise the extracted patterns so that they can be counted more easily. This phase ends by writing out the consolidated data frame to a .csv for manual inspection. I could not find a feasible way of identifying whether or not the nouns matched in the extraction phase are person-nouns or not. As the list is not a totally unreasonable length (in the hundreds) I found it workable to open in excel, order alphabetically by 'Person-first' and just scan through to check each match manually. I then ordered alphabetically by 'Identity-first' to check those too. As an example, there were quite a few examples of \"autistic testing\" or \"autistic behaviour\" that were eliminated because, although they matched the identity-first pattern, they are not about people and so are not example of identity-first language. \n",
    "\n",
    "Coincidentally, during this manual checking part of the consolidation phase I learned that, in the context of human genetics research \"proband\" is a person-noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d91446",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_sentences[(matched_sentences['Person-first'] != '') | (matched_sentences['Identity-first'] != '')]\n",
    "                                                     # keep only rows w/ non-null 'Person-first' and/or 'Identity-first' columns\n",
    "len(matched_patterns)                                # check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58536fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_patterns.explode('Person-first')    # explode 'Person-first' column to create 1 row per match\n",
    "                                                               # if there were two matches within the same sentence\n",
    "len(matched_patterns)                                          # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80451426",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_patterns.explode('Identity-first')  # Do the same for 'Identity-first' column\n",
    "len(matched_patterns)                                          # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns                                               # have a look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f32a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lem = WordNetLemmatizer()                         # Define a short way to call the WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcca95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_lemma_list = []                            # Create an empty list for output of lemmatising the person-first patterns\n",
    "lemmatized = []                                   # create an empty list to act as a temp variable for the appending process\n",
    "for phrase in matched_patterns['Person-first']:   # start for loop looking at each pattern in the person-first pattern column\n",
    "    x = str(phrase)                               # hold the current pattern\n",
    "    words = x.split()                             # split the current pattern into words\n",
    "    for word in words :                           # start a for loop looing at each word in the current pattern\n",
    "        lemword = Lem.lemmatize(word)             # hold a lemmatised copy of the current word\n",
    "        lemmatized.append(lemword)                # append the lemmatised copy of the current word to the temp variable\n",
    "    person_lemma_list.append(lemmatized)          # append the temp variable with the lemmatised words to the output list\n",
    "    lemmatized = []                               # ensure the temp variable is empty\n",
    "\n",
    "person_lemma_list                                 # have a look at the output list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69719ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_lemma_list = []                             # repeat the same thing again for identity-first column\n",
    "lemmatized = []\n",
    "for phrase in matched_patterns['Identity-first']:\n",
    "    x = str(phrase)\n",
    "    words = x.split()\n",
    "    for word in words :\n",
    "        lemword = Lem.lemmatize(word)\n",
    "        lemmatized.append(lemword)\n",
    "    identity_lemma_list.append(lemmatized)\n",
    "    lemmatized = []\n",
    "\n",
    "identity_lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns['Person-first_lemmatized'] = person_lemma_list    # copy the person-first output to new column in data frame \n",
    "matched_patterns['Identy-first_lemmatized'] = identity_lemma_list  # copy the identity-first output to new column in data frame \n",
    "matched_patterns                                                   # have a look at the data frame with its new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_patterns_for_manual_review.to_csv('..\\\\output\\\\text_match_results.csv')        \n",
    "                                                            # Write the data frame to a .csv for manual processing in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2281a",
   "metadata": {},
   "source": [
    "## Chart person first or identity first by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_first = pd.read_csv('..\\\\..\\\\2023_Second_analysis\\\\output\\\\text_match_results.csv')\n",
    "person_identity_first = person_identity_first.dropna(how='all')\n",
    "person_identity_first['Year'] = person_identity_first['Year'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2718e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_count = person_identity_first.groupby(['Year'])['Person-first'].count()\n",
    "identity_count = person_identity_first.groupby(['Year'])['Identity-first'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_count=pd.concat([person_count,identity_count],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_count.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fe19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_examples = person_identity_first.groupby(['Person-first'])['Person-first'].count()\n",
    "identity_examples = person_identity_first.groupby(['Identity-first'])['Identity-first'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1443d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_examples=pd.concat([person_examples,identity_examples],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_examples.sort_values(by=['Person-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_examples.sort_values(by=['Identity-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6184b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_examples.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f05d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_person = person_identity_first[~person_identity_first['Person-first'].isnull()]\n",
    "len(has_person)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_identity = person_identity_first[~person_identity_first['Identity-first'].isnull()]\n",
    "len(has_identity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b82b88",
   "metadata": {},
   "source": [
    "## Count abstracts by the structures they use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd85bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_by_title = person_identity_first.groupby(['Title'])['Person-first'].count()\n",
    "identity_by_title = person_identity_first.groupby(['Title'])['Identity-first'].count()\n",
    "title = pd.concat([person_by_title,identity_by_title],axis=1)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.sort_values(by=['Identity-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f461ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.sort_values(by=['Person-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Person-first','Identity-first']\n",
    "filter_ = (title[columns] > 0).all(axis=1)\n",
    "title[filter_]\n",
    "len(title[filter_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "title[filter_].sort_values(by=['Person-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13737d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title[filter_].sort_values(by=['Identity-first'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e03f1",
   "metadata": {},
   "source": [
    "## Word counts by part of speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1452278",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_p_i = []\n",
    "\n",
    "for token in p_i_doc:\n",
    "    this_token = [token.text, token.lemma_, token.pos_, token.tag_]\n",
    "    if any (s in token.text for s in ['autistic', 'Autistic', 'autism', 'Autism', 'ASD', 'asd', 'Asperger', 'asperger']):\n",
    "        POS_p_i.append(this_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175766b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\\\counts\\\\ESHG\\\\POS.csv', \"w\", encoding='utf8') as outfile:\n",
    "        write = csv.writer(outfile)\n",
    "        for item in POS_p_i:\n",
    "            write.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918896cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879661b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f_lower = [word.lower() for word in person_first]     # make those tokens lowercase\n",
    "p_f_no_punct = [w.translate(table_punctuation) for w in p_f_lower] # remove the punctuation\n",
    "p_f_no_space = (list(filter(lambda x: x, p_f_no_punct)))           # remove any extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for saving output\n",
    "os.makedirs('folder/subfolder', exist_ok=True)  \n",
    "df.to_csv('folder/subfolder/out.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
