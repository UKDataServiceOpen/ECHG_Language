{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-husband",
   "metadata": {},
   "source": [
    "# Splitting a .pdf, or removing unnecessary pages from a .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-pendant",
   "metadata": {},
   "source": [
    "## Install and import necessary things\n",
    "\n",
    "This, and all the other jupyter notebooks in this repository, start with installing and/or importing all the packages needed to perform the actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nuclear-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# installing necessary pdf conversion package via pip\n",
    "# the '%%capture' at the top of this cell suppresses the output (which is normally quite long and annoying looking). \n",
    "# You can remove or comment it out if you prefer to see the output. \n",
    "\n",
    "import os\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-wheat",
   "metadata": {},
   "source": [
    "## Define the function\n",
    "\n",
    "First, define a function that takes a .pdf filename and two page numbers and returns a smaller .pdf that only contains the pages between the provided page numbers. \n",
    "\n",
    "This code is adapted slightly from the original here -> https://gist.github.com/khanfarhan10/464d44086327369953327a7320716100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_split(fname, start, end=None):\n",
    "    print('pdf_split', fname, start, end)\n",
    "\n",
    "    inputpdf = PdfFileReader(open(fname, \"rb\"))\n",
    "    output = PdfFileWriter()\n",
    "\n",
    "    # turn 1,4 to 0,3\n",
    "    num_pages = inputpdf.numPages\n",
    "    if start:\n",
    "        start-=1\n",
    "    if not start:\n",
    "        start=0\n",
    "    if not end or end > num_pages:\n",
    "        end=num_pages\n",
    "\n",
    "    get_pages = list(range(start,end))\n",
    "    #print('get_pages', get_pages, 'of', num_pages)\n",
    "    # get_pages [0, 1, 2, 3]\n",
    "\n",
    "    for i in range(start,end):\n",
    "        if i < start:\n",
    "            continue\n",
    "        #output = PdfFileWriter()\n",
    "        output.addPage(inputpdf.getPage(i))\n",
    "\n",
    "    fname_no_pdf = row[0]\n",
    "    if row[0][:-4].lower() == '.pdf':\n",
    "        fname_no_pdf = row[0][:-4]\n",
    "    out_filename = f\"{outfolder + fname_no_pdf}\"\n",
    "    with open(out_filename, \"wb\") as outputStream:\n",
    "        output.write(outputStream)\n",
    "    print('saved', out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-regulation",
   "metadata": {},
   "source": [
    "## Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-mileage",
   "metadata": {},
   "source": [
    "###  Test run\n",
    "\n",
    "First off, we check the contents of the test folder. \n",
    "\n",
    "Then, we create a list of lists that holds the arguments needed to run the function. The start and end numbers have no real significance, they are just numbers used to test. Importantly, they are within the bounds of the .pdf which requires you to know how many pages are in it. \n",
    "\n",
    "Finally, a little for-loop runs the function on each item in the defined list of list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "victorian-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_pdf_1.pdf', 'input_pdf_2.pdf', 'input_pdf_3.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\\\\raw_pdfs\\\\Test\") # This is how to see the contents of any folders shown in the last contents check\n",
    "                            # For example, 'input_pdfs' which is likely to contain things we want to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "annual-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split_test = [[\"input_pdf_1.pdf\", 0, 0],\n",
    " [\"input_pdf_2.pdf\", 1, 0],\n",
    " [\"input_pdf_3.pdf\", 2, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polar-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_split ..\\raw_pdfs\\Test\\input_pdf_1.pdf 0 0\n",
      "saved ..\\input_pdfs\\Test\\input_pdf_1.pdf\n",
      "pdf_split ..\\raw_pdfs\\Test\\input_pdf_2.pdf 1 0\n",
      "saved ..\\input_pdfs\\Test\\input_pdf_2.pdf\n",
      "pdf_split ..\\raw_pdfs\\Test\\input_pdf_3.pdf 2 5\n",
      "saved ..\\input_pdfs\\Test\\input_pdf_3.pdf\n"
     ]
    }
   ],
   "source": [
    "for row in to_split_test:\n",
    "    folder = \"..\\\\raw_pdfs\\\\Test\\\\\"\n",
    "    outfolder =  \"..\\\\input_pdfs\\\\Test\\\\\"\n",
    "    fname = folder + row[0]\n",
    "    pdf_split(fname, row[1], row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-council",
   "metadata": {},
   "source": [
    "The output of the for-loop suggests it all went well, but you may want to inspect the files to double check every thing went as you intended. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-chain",
   "metadata": {},
   "source": [
    "### Run on files of interest\n",
    "\n",
    "Assuming there were no major problems, the process is repeated for the files of interest:\n",
    "\n",
    "* check the contents of the relevant folder,\n",
    "* define a list of lists to hold the function arguments, and\n",
    "* run the for-loop to apply the function to the defined list of list. \n",
    "\n",
    "\n",
    "As before, defining the start and end numbers is a bit of a manual process. I had to open the files, identify the first page that I wanted to keep and the last page that I wanted to keep (paying special attention to the actual .pdf page number rather than the page numbers within the document). \n",
    "\n",
    "I also strongly recommend a lot of manual checking to be sure it came out correctly. I had to edit the list a couple of time and re-run the code to get everything correct. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "traditional-ability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESHG2001abstractICHG.pdf',\n",
       " 'ESHG2002Abstracts.pdf',\n",
       " 'ESHG2003Abstracts.pdf',\n",
       " 'ESHG2004Abstracts.pdf',\n",
       " 'ESHG2005Abstracts.pdf',\n",
       " 'ESHG2006Abstracts.pdf',\n",
       " 'ESHG2007Abstracts.pdf',\n",
       " 'ESHG2008Abstracts.pdf',\n",
       " 'ESHG2009Abstracts.pdf',\n",
       " 'ESHG2010Abstracts.pdf',\n",
       " 'ESHG2011Abstracts.pdf',\n",
       " 'ESHG2012Abstracts.pdf',\n",
       " 'ESHG2013Abstracts.pdf',\n",
       " 'ESHG2014Abstracts.pdf',\n",
       " 'ESHG2015Abstracts.pdf',\n",
       " 'ESHG2016Abstracts.pdf',\n",
       " 'ESHG2017 electronic posters.pdf',\n",
       " 'ESHG2017 oral presentations.pdf',\n",
       " 'ESHG2017 posters.pdf',\n",
       " 'ESHG2018 electronic posters.pdf',\n",
       " 'ESHG2018 EMPAG.pdf',\n",
       " 'ESHG2018 oral presentation.pdf',\n",
       " 'ESHG2018 posters.pdf',\n",
       " 'ESHG2019 oral presentation.pdf',\n",
       " 'ESHG2019 posters.pdf',\n",
       " 'ESHG2019 posters2.pdf',\n",
       " 'ESHG2020 eposters.pdf',\n",
       " 'ESHG2020 interactive eposter.pdf',\n",
       " 'ESHG2020 oral presentation.pdf',\n",
       " 'ESHG2021 eposters.pdf',\n",
       " 'ESHG2021 oral presentations.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\\\\..\\\\PIFL\\\\raw_pdfs\\\\ESHG\") # This is how to see the contents of any folders shown in the last contents check\n",
    "                            # For example, 'input_pdfs' which is likely to contain things we want to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "given-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESHG2001abstractICHG.pdf',\n",
       " 'ESHG2002Abstracts.pdf',\n",
       " 'ESHG2003Abstracts.pdf',\n",
       " 'ESHG2004Abstracts.pdf',\n",
       " 'ESHG2005Abstracts.pdf',\n",
       " 'ESHG2006Abstracts.pdf',\n",
       " 'ESHG2007Abstracts.pdf',\n",
       " 'ESHG2008Abstracts.pdf',\n",
       " 'ESHG2009Abstracts.pdf',\n",
       " 'ESHG2010Abstracts.pdf',\n",
       " 'ESHG2011Abstracts.pdf',\n",
       " 'ESHG2012Abstracts.pdf',\n",
       " 'ESHG2013Abstracts.pdf',\n",
       " 'ESHG2014Abstracts.pdf',\n",
       " 'ESHG2015Abstracts.pdf',\n",
       " 'ESHG2016Abstracts.pdf',\n",
       " 'ESHG2017 electronic posters.pdf',\n",
       " 'ESHG2017 oral presentations.pdf',\n",
       " 'ESHG2017 posters.pdf',\n",
       " 'ESHG2018 electronic posters.pdf',\n",
       " 'ESHG2018 EMPAG.pdf',\n",
       " 'ESHG2018 oral presentation.pdf',\n",
       " 'ESHG2018 posters.pdf',\n",
       " 'ESHG2019 oral presentation.pdf',\n",
       " 'ESHG2019 posters.pdf',\n",
       " 'ESHG2019 posters2.pdf',\n",
       " 'ESHG2020 eposters.pdf',\n",
       " 'ESHG2020 interactive eposter.pdf',\n",
       " 'ESHG2020 oral presentation.pdf',\n",
       " 'ESHG2021 eposters.pdf',\n",
       " 'ESHG2021 oral presentations.pdf']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\\\\..\\\\PIFL\\\\raw_pdfs\\\\ESHG\") # This is how to see the contents of any folders shown in the last contents check\n",
    "                            # For example, 'input_pdfs' which is likely to contain things we want to import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-linux",
   "metadata": {},
   "source": [
    "In the process of manually checking the ESHG files, I noticed that only the pre-2017 files needed to be trimmed. The more recent files do not contain cover pages, indices, adverts, etc. Winning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "curious-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = [[\"ESHG2001abstractICHG.pdf\", 64, 434],\n",
    " [\"ESHG2002Abstracts.pdf\", 54, 327],\n",
    " [\"ESHG2003Abstracts.pdf\", 44, 261],\n",
    " [\"ESHG2004Abstracts.pdf\", 58, 373],\n",
    " [\"ESHG2005Abstracts.pdf\", 55, 388],\n",
    " [\"ESHG2006Abstracts.pdf\", 74, 410],\n",
    " [\"ESHG2007Abstracts.pdf\", 5, 351],\n",
    " [\"ESHG2008Abstracts.pdf\", 5, 469],\n",
    " [\"ESHG2009Abstracts.pdf\", 6, 401],\n",
    " [\"ESHG2010Abstracts.pdf\", 6, 400],\n",
    " [\"ESHG2011Abstracts.pdf\", 5, 484],\n",
    " [\"ESHG2012Abstracts.pdf\", 6, 438],\n",
    " [\"ESHG2013Abstracts.pdf\", 6, 611],\n",
    " [\"ESHG2014Abstracts.pdf\", 6, 518],\n",
    " [\"ESHG2015Abstracts.pdf\", 6, 485],\n",
    " [\"ESHG2016Abstracts.pdf\", 6, 506]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reasonable-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_split ..\\raw_pdfs\\ESHG\\ESHG2001abstractICHG.pdf 64 434\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PdfFileReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3104d0512c83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moutfolder\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m\"..\\\\input_pdfs\\\\ESHG\\\\\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpdf_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-bf818b8b8341>\u001b[0m in \u001b[0;36mpdf_split\u001b[1;34m(fname, start, end)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pdf_split'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minputpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PdfFileReader' is not defined"
     ]
    }
   ],
   "source": [
    "for row in to_split:\n",
    "    folder = \"..\\\\raw_pdfs\\\\ESHG\\\\\"\n",
    "    outfolder =  \"..\\\\input_pdfs\\\\ESHG\\\\\"\n",
    "    fname = folder + row[0]\n",
    "    pdf_split(fname, row[1], row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-headquarters",
   "metadata": {},
   "source": [
    "As a note, there is an error message (PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected.) after the 2004 file. \n",
    "\n",
    "Online advice suggests this is an encoding error coming from how the .pdf file was created that let's it be read but not handled in the standard way. The solution seems to be to open it in Adobe and save it under a new file name. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
