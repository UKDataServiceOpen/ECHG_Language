{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "positive-implementation",
   "metadata": {},
   "source": [
    "# Converting .pdf files to text files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-description",
   "metadata": {},
   "source": [
    "## Install and import necessary things\n",
    "\n",
    "Start off by installing the PyPDF2 module (if you don't already have it installed) and importing that module so that it can be used in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eligible-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\python39\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from PyPDF2) (4.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# installing necessary pdf conversion package via pip\n",
    "!pip install PyPDF2             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stupid-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules (first for displaying screenshots, second for converting pdfs)\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import PyPDF2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-charity",
   "metadata": {},
   "source": [
    "## Create and/or check the input .pdf\n",
    "\n",
    "I first created 2 test files in word and then printed each of them off to .pdf. I specifically put a few key features into these files to test how the text would be converted, such as a heading, multiple blank lines between text, an image with a caption, multiple pages, and two column text. \n",
    "\n",
    "I then saved these new .pdfs (and screenshots of both) into the same location as my .ipynb so that I can \n",
    "* 1 - paste in the images to show how the .pdfs looked to begin with (see next cell) and\n",
    "* 2 - import the .pdfs so that PyPDF2 can convert them (see cell after next). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arctic-latino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='..\\images\\Input_pdf_image_1.png'></td><td><img src='..\\images\\Input_pdf_image_2.png'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<table><tr><td><img src='..\\images\\Input_pdf_image_1.png'></td><td><img src='..\\images\\Input_pdf_image_2.png'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "wooden-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='..\\\\input_pdfs\\\\input_pdf_1.pdf'>\n"
     ]
    }
   ],
   "source": [
    "# creating .pdf file objects from existing .pdfs in the same folder as this .ipynb code\n",
    "# this ipmorts the .pdfs and creates accessible objects for the PyPDF2 module to work with\n",
    "\n",
    "pdfFileObj_1 = open('..\\input_pdfs\\Test\\input_pdf_1.pdf', 'rb') \n",
    "pdfFileObj_2 = open('..\\input_pdfs\\Test\\input_pdf_2.pdf', 'rb') \n",
    "print(pdfFileObj_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-sierra",
   "metadata": {},
   "source": [
    "## Convert and check the .pdf objects\n",
    "\n",
    "The first step is to create a PyPDF2 oject from the imported .pdf. This allows you to do things like:\n",
    "* check how many pages are in the original .pdf, \n",
    "* convert some or all of those pages to page objects, and\n",
    "* then extract the text from those page ojbects (optionally saving the text for later analysis). \n",
    "\n",
    "Of course, good coding etiquette suggests you should always close any opened files when you are done with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ordered-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating .pdf reader objects, which the module will use for the actual conversion work\n",
    "pdfReader_1 = PyPDF2.PdfFileReader(pdfFileObj_1) \n",
    "pdfReader_2 = PyPDF2.PdfFileReader(pdfFileObj_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-survey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cosmetic-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# printing number of pages in each .pdf file \n",
    "print(pdfReader_1.numPages) \n",
    "print(pdfReader_2.numPages) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-metallic",
   "metadata": {},
   "source": [
    "So far so good. We have the .pdfs imported, converted to module specific objects, and the module has correctly identified the number of pages in each. But really, we need to know how well the module can recognise the text within those objects cause I deliberately made that text a bit tricky. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-ranch",
   "metadata": {},
   "source": [
    "## Get individual pages, extract text, save it as strings, etc. \n",
    "\n",
    "Now, we get down to the real work. We want to  \n",
    "* convert some or all of those pages to page objects, and\n",
    "* then extract the text from those page ojbects, \n",
    "* (optionally) save that text as string objects for later analysis, and \n",
    "* tidy up (good coding etiquette suggests you should always close any opened files when you are done with them) . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "global-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating page objects for each page\n",
    "# something to note here - the pages start counting from 0 so you get page 1 of our first test .pdf\n",
    "#                          by asking getPage to getPage(0). \n",
    "#                          In turn, when we want to get both pages from the second test .pdf, we ask for \n",
    "#                          getPage(0) and also getPage(1)\n",
    "pageObj_1_1 = pdfReader_1.getPage(0) \n",
    "pageObj_2_1 = pdfReader_2.getPage(0)\n",
    "pageObj_2_2 = pdfReader_2.getPage(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "announced-bolivia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input .pdf for testing \n",
      "Test text.  \n",
      "One.  \n",
      "Two.  \n",
      "Three.  \n",
      "Figure 1 - A plane with caption to test caption conversion. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracting text from page to print on screen\n",
    "print(pageObj_1_1.extractText()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci \n",
      "\n",
      "velit...\" \n",
      "\n",
      "\"There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is \n",
      "\n",
      "pain...\" \n",
      "\n",
      "What is Lorem Ipsum? \n",
      "\n",
      "Lorem Ipsum is simply dummy text of the \n",
      "\n",
      "printing  and  typesetting  industry.  Lorem \n",
      "\n",
      "Ipsum  has  been  the  industry's  standard \n",
      "\n",
      "dummy text ever since the 1500s, when an \n",
      "\n",
      "unknown printer took a galley of type and \n",
      "\n",
      "scrambled  it  to  make  a  type  specimen \n",
      "\n",
      "book.  It  has  survived  not  only  five \n",
      "\n",
      "centuries, but also the leap into electronic \n",
      "\n",
      "typesetting,  remaining  essentially \n",
      "\n",
      "unchanged.  It  was  popularised  in  the \n",
      "\n",
      "1960s  with  the  release of  Letraset  sheets \n",
      "\n",
      "containing  Lorem  Ipsum  passages,  and \n",
      "\n",
      "more  recently  with  desktop  publishing \n",
      "\n",
      "software  like  Aldus  PageMaker  including \n",
      "\n",
      "versions of Lorem Ipsum. \n",
      "\n",
      "Why do we use it? \n",
      "\n",
      "It  is  a  long  established  fact  that  a  reader \n",
      "\n",
      "will be distracted by the readable content \n",
      "\n",
      "of  a  page  when  looking  at  its  layout.  The \n",
      "\n",
      "point of using Lorem Ipsum is that it has a \n",
      "\n",
      "more-or-less normal distribution of letters, \n",
      "\n",
      "as opposed to using 'Content here, content \n",
      "\n",
      "here', making it look like readable English. \n",
      "\n",
      "Many  desktop  publishing  packages  and \n",
      "\n",
      "web page editors now use Lorem Ipsum as \n",
      "\n",
      "their default model text, and a search for \n",
      "\n",
      "'lorem ipsum' will uncover many web sites \n",
      "\n",
      "still in their infancy. Various versions have \n",
      "\n",
      "evolved  over  the  years,  sometimes  by \n",
      "\n",
      "accident, sometimes on purpose (injected \n",
      "\n",
      "humour and the like). \n",
      " Where does it come from? \n",
      "\n",
      "Contrary to popular belief, Lorem Ipsum is \n",
      "\n",
      "not  simply  random  text.  It  has  roots  in  a \n",
      "\n",
      "piece  of  classical  Latin  literature  from  45 \n",
      "\n",
      "BC, making it over 2000 years old. Richard \n",
      "\n",
      "McClintock, a Latin professor at Hampden-\n",
      "\n",
      "Sydney College  in Virginia,  looked  up  one \n",
      "\n",
      "of  the  more  obscure  Latin  words, \n",
      "\n",
      "consectetur, from a Lorem Ipsum passage, \n",
      "\n",
      "and going through the cites of the word in \n",
      "\n",
      "classical  literature,  discovered  the \n",
      "\n",
      "undoubtable source. Lorem Ipsum comes \n",
      "\n",
      "from  sections  1.10.32  and  1.10.33  of  \"de \n",
      "\n",
      "Finibus  Bonorum  et  Malorum\"  (The \n",
      "\n",
      "Extremes  of  Good  and  Evil)  by  Cicero, \n",
      "\n",
      "written in 45 BC. This book is a treatise on \n",
      "\n",
      "the  theory  of  ethics,  very  popular  during \n",
      "\n",
      "the  Renaissance.  The  first  line  of  Lorem \n",
      "\n",
      "Ipsum,  \"Lorem  ipsum  dolor  sit  amet..\", \n",
      "\n",
      "comes from a line in section 1.10.32. \n",
      "\n",
      "The standard chunk of Lorem Ipsum used \n",
      "\n",
      "since  the  1500s  is  reproduced  below  for \n",
      "\n",
      "those  interested.  Sections  1.10.32  and \n",
      "\n",
      "1.10.33  from  \"de  Finibus  Bonorum  et \n",
      "\n",
      "Malorum\" by Cicero are also reproduced in \n",
      "\n",
      "their exact original form, accompanied by \n",
      "\n",
      "English versions from the 1914 translation \n",
      "\n",
      "by H. Rackham. \n",
      "\n",
      "Where can I get some? \n",
      "\n",
      "There are many variations of passages of \n",
      "\n",
      "Lorem  Ipsum  available,  but  the  majority \n",
      "\n",
      "have suffered alteration in some form, by \n",
      "\n",
      "injected  humour,  or  randomised  words \n"
     ]
    }
   ],
   "source": [
    "# extracting text from page to print on screen\n",
    "print(pageObj_2_1.extractText()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bigger-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which don't look even slightly believable. If \n",
      "\n",
      "you are going to use  a passage  of  Lorem \n",
      "\n",
      "Ipsum,  you  need  to  be  sure  there  isn't \n",
      "\n",
      "anything  embarrassing  hidden  in  the \n",
      "\n",
      "middle  of  text.  All  the  Lorem  Ipsum \n",
      "\n",
      "generators on the Internet tend to repeat \n",
      "\n",
      "predefined  chunks  as  necessary,  making \n",
      "\n",
      "this the first true generator on the Internet. \n",
      "\n",
      "It uses a dictionary of over 200 Latin words, \n",
      "\n",
      "combined  with  a  handful  of  model \n",
      "\n",
      "sentence  structures,  to  generate  Lorem \n",
      "\n",
      "Ipsum  which  looks  reasonable.  The \n",
      "\n",
      "generated  Lorem  Ipsum  is  therefore \n",
      "\n",
      "always  free  from  repetition,  injected \n",
      "\n",
      "humour, or non-characteristic words etc. \n"
     ]
    }
   ],
   "source": [
    "# extracting text from page to print on screen\n",
    "print(pageObj_2_2.extractText()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-terrorism",
   "metadata": {},
   "source": [
    "So, good news. This .pdf conversion module has successfully recognised that input_pdf_2 was structured in two columns and it has converted the text appropriately (ish) with the text flowing properly from the end of one line in a column to the start of the next line *in the same column* rather than reading on to the equivalent line in the next column. \n",
    "\n",
    "It might be better if the lines were not cut short to replicate the actual number of words in each column as they appear in the text, but that is a step for later on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specific-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting text from page to save for later use, in this case as a string object\n",
    "test_file_1 = (pageObj_1_1.extractText()) \n",
    "type(test_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strange-nowhere",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-84f410d60aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save that string object in a .csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# why not a .txt file? We will probably want other data, like the page number, original file, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# with the file open in \"write\" mode, and giving it a shorter name (f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'csv'"
     ]
    }
   ],
   "source": [
    "# save that string object in a .csv file\n",
    "# why not a .txt file? We will probably want other data, like the page number, original file, etc. \n",
    "with open(test_file_1.csv, \"w\", newline=\"\")as f: # with the file open in \"write\" mode, and giving it a shorter name (f)\n",
    "    f.write(\"\\n\".join(test_file_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "figured-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create folder: already exists\n"
     ]
    }
   ],
   "source": [
    "# Create a downloads folder\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./output_texts\")\n",
    "except:\n",
    "    print(\"Unable to create folder: already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results to a .csv file\n",
    "\n",
    "variables = [\"pdf_name\", \"page\", \"text\"] # define variable names for the file\n",
    "outfile = \"./output_texts/test\" + date + \".csv\" # define a file for writing the results, \n",
    "                                                # real results will want to change \"test\" to something else\n",
    "obs = pdf_name, page, text # define an observation (row)\n",
    "\n",
    "with open(outfile, \"w\", newline=\"\") as f: # with the file open in \"write\" mode, and giving it a shorter name (f)\n",
    "    writer = csv.writer(f) # define a 'writer' object that allows us to export information to a CSV\n",
    "    writer.writerow(variables) # write the variable names to the first row of the file\n",
    "    writer.writerow(obs) # write the observation to the next row in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reflected-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the pdf file object \n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-medicine",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This is a great first start, but it is not the whole project. Prior to this step, we need to create one or more scripts to webscrape the necessarry .pdf files from the medical journals - e.g. from https://www.nature.com/ejhg/volumes/30\n",
    "\n",
    "We would also need to ensure the scraped .pdf files have a consistent naming structure and are stored in an accessible place. This could easily be built into the webscraping script, but an extra step to check is never a bad thing. \n",
    "\n",
    "Then, we would need to embed the steps from this .ipynb into a loop that \n",
    "* imports a .pdf from the designated folder, \n",
    "* converts it to a pdfReader opbject, \n",
    "* counts the pages in that object, \n",
    "* creates page objects from each page, \n",
    "* extracts the text from each page, \n",
    "* appends that text to a saved string object with an appropriate name based off the original file name, \n",
    "* closes the pdfReader object and other other relevant objects, and \n",
    "* proceeds to the next .pdf. \n",
    "\n",
    "After that, we would then proceed to the actual text-mining steps (cleaning the text, stemming or lemmatising it, extracting the relevant person-first and identify-first language and any contexts that seem relevant, etc. )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-lotus",
   "metadata": {},
   "source": [
    "## Making the whole thing less of a pain in the neck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-cycle",
   "metadata": {},
   "source": [
    "The above steps works, but are manual. That is to say, we need to run a line of code for each .pdf per step. \n",
    "\n",
    "When we only have 2 test .pdf files, so this manual process is fine. But we are hoping to turn this into a process we can run this on lots of .pdf files and it would get real tedious REAL fast if we had to do this entirely manually. \n",
    "\n",
    "So let's start making a more automatic process that will take a directory (folder) as input and runs the relevant steps on each item in that folder, ultimately outputing a file into a separate folder at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "other-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules (first for displaying screenshots, second for converting pdfs)\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import PyPDF2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acquired-engineering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mzyssjkc\\\\GitWork\\\\Person_Identy_First_Language\\\\code'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    os.getcwd()   # This is how to see our Current Working Directory or where the computer will interpret as \"where we are now\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "careful-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'code',\n",
       " 'downloads',\n",
       " 'images',\n",
       " 'input_pdfs',\n",
       " 'LICENSE',\n",
       " 'output_texts',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\") # This is how to the contents of the folder that is one \"up\" from where we are now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upset-cameroon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESHG', 'Test']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\\input_pdfs\") # This is how to the contents of the input_pdfs folder where we expect to see our content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valued-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory for importing files\n",
    "in_directory = '..\\input_pdfs\\Test'\n",
    "out_directory= '..\\output_texts'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recreational-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that: \n",
    "# this ipmorts the .pdfs and creates accessible objects for the PyPDF2 module to work with\n",
    "\n",
    "def convert_pdfs(input_directory):                              # takes the defined directory as input\n",
    "    pdf_objects = []                                            # create an empty list holding .pdfs in a easy-read format\n",
    "    counter = 0                                                 # a counter starting at zero ensures unique file names\n",
    "    for filename in os.listdir(in_directory):                      # create a for loop that looks at each file\n",
    "        shortname = os.path.splitext(filename)[0]               # strip off the '.pdf' portion of the file name\n",
    "        output_file = shortname + str(counter)                  # define the easy-read name (shortname plus unique number)\n",
    "        counter = counter + 1                                   # add 1 to the counter so numbers don't repeat\n",
    "        pdf_objects.append(output_file)                         # add the easy-read name to the list for easy-read names\n",
    "        output_file = open(directory + \"\\\\\" + filename ,'rb')   # the original code, that imports the pdf object\n",
    "    print(pdf_objects)                                          # an optional sense check to see the easy-read names\n",
    "    for pdf_object in pdf_objects:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "complicated-symbol",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-63-da26f3e798d2>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-63-da26f3e798d2>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    counter = 0                                                 # a counter starting at zero ensures unique file names\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# define a function that: \n",
    "# this ipmorts the .pdfs and creates accessible objects for the PyPDF2 module to work with\n",
    "\n",
    "def convert_pdfs(input_directory, out_directory):               # takes a pre-defined input directory as an argument\n",
    "    counter = 0                                                 # a counter starting at zero ensures unique file names\n",
    "    try:                                                        # also takes a pre-defined output directory as an argument\n",
    "        os.mkdir(out_directory)\n",
    "    for filename in os.listdir(in_directory):                      # create a for loop that looks at each file\n",
    "        shortname = os.path.splitext(filename)[0]               # strip off the '.pdf' portion of the file name\n",
    "        output_file = shortname + str(counter)                  # define the easy-read name (shortname plus unique number)\n",
    "        output_file_name = output_file\n",
    "        counter = counter + 1                                   # add 1 to the counter so numbers don't repeat\n",
    "        output_file = open(directory + \"\\\\\" + filename ,'rb')   # Imports a .pdf object for each numbered input files. \n",
    "        output_file = PyPDF2.PdfFileReader(output_file)         # overwrite the output with a converted pdf reader file\n",
    "        number_of_pages = output_file.numPages                  # save the number of pages in this .pdf reader file\n",
    "        variables = [\"pdf_name\", \"page\", \"text\"]                # define variable names for the file\n",
    "        outfile = outdirectory + \".csv\"                         # define a file for writing the results\n",
    "        print(outfile)\n",
    "        #obs = pdf_name, page, text # define an observation (row)\n",
    "        #with open(outfile, \"w\", newline=\"\") as f:               # with the file open in \"write\" mode, and giving it a shorter name (f)\n",
    "    # writer = csv.writer(f) # define a 'writer' object that allows us to export information to a CSV\n",
    "    # writer.writerow(variables) # write the variable names to the first row of the file\n",
    "    # writer.writerow(obs) # write the observation to the next row in the file\n",
    "        while number_of_pages > 0:\n",
    "            page_object = str(output_file_name) + str(number_of_pages)\n",
    "            number_of_pages -= 1\n",
    "            page_object = output_file.getPage(number_of_pages)\n",
    "            output_text = (page_object.extractText())            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "blocked-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_pdf_101\n",
      "0\n",
      " Input .pdf for testing \n",
      "Test text.  \n",
      "One.  \n",
      "Two.  \n",
      "Three.  \n",
      "Figure 1 - A plane with caption to test caption conversion. \n",
      "\n",
      "input_pdf_212\n",
      "1\n",
      "which don't look even slightly believable. If \n",
      "\n",
      "you are going to use  a passage  of  Lorem \n",
      "\n",
      "Ipsum,  you  need  to  be  sure  there  isn't \n",
      "\n",
      "anything  embarrassing  hidden  in  the \n",
      "\n",
      "middle  of  text.  All  the  Lorem  Ipsum \n",
      "\n",
      "generators on the Internet tend to repeat \n",
      "\n",
      "predefined  chunks  as  necessary,  making \n",
      "\n",
      "this the first true generator on the Internet. \n",
      "\n",
      "It uses a dictionary of over 200 Latin words, \n",
      "\n",
      "combined  with  a  handful  of  model \n",
      "\n",
      "sentence  structures,  to  generate  Lorem \n",
      "\n",
      "Ipsum  which  looks  reasonable.  The \n",
      "\n",
      "generated  Lorem  Ipsum  is  therefore \n",
      "\n",
      "always  free  from  repetition,  injected \n",
      "\n",
      "humour, or non-characteristic words etc. \n",
      "input_pdf_211\n",
      "0\n",
      "\"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci \n",
      "\n",
      "velit...\" \n",
      "\n",
      "\"There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is \n",
      "\n",
      "pain...\" \n",
      "\n",
      "What is Lorem Ipsum? \n",
      "\n",
      "Lorem Ipsum is simply dummy text of the \n",
      "\n",
      "printing  and  typesetting  industry.  Lorem \n",
      "\n",
      "Ipsum  has  been  the  industry's  standard \n",
      "\n",
      "dummy text ever since the 1500s, when an \n",
      "\n",
      "unknown printer took a galley of type and \n",
      "\n",
      "scrambled  it  to  make  a  type  specimen \n",
      "\n",
      "book.  It  has  survived  not  only  five \n",
      "\n",
      "centuries, but also the leap into electronic \n",
      "\n",
      "typesetting,  remaining  essentially \n",
      "\n",
      "unchanged.  It  was  popularised  in  the \n",
      "\n",
      "1960s  with  the  release of  Letraset  sheets \n",
      "\n",
      "containing  Lorem  Ipsum  passages,  and \n",
      "\n",
      "more  recently  with  desktop  publishing \n",
      "\n",
      "software  like  Aldus  PageMaker  including \n",
      "\n",
      "versions of Lorem Ipsum. \n",
      "\n",
      "Why do we use it? \n",
      "\n",
      "It  is  a  long  established  fact  that  a  reader \n",
      "\n",
      "will be distracted by the readable content \n",
      "\n",
      "of  a  page  when  looking  at  its  layout.  The \n",
      "\n",
      "point of using Lorem Ipsum is that it has a \n",
      "\n",
      "more-or-less normal distribution of letters, \n",
      "\n",
      "as opposed to using 'Content here, content \n",
      "\n",
      "here', making it look like readable English. \n",
      "\n",
      "Many  desktop  publishing  packages  and \n",
      "\n",
      "web page editors now use Lorem Ipsum as \n",
      "\n",
      "their default model text, and a search for \n",
      "\n",
      "'lorem ipsum' will uncover many web sites \n",
      "\n",
      "still in their infancy. Various versions have \n",
      "\n",
      "evolved  over  the  years,  sometimes  by \n",
      "\n",
      "accident, sometimes on purpose (injected \n",
      "\n",
      "humour and the like). \n",
      " Where does it come from? \n",
      "\n",
      "Contrary to popular belief, Lorem Ipsum is \n",
      "\n",
      "not  simply  random  text.  It  has  roots  in  a \n",
      "\n",
      "piece  of  classical  Latin  literature  from  45 \n",
      "\n",
      "BC, making it over 2000 years old. Richard \n",
      "\n",
      "McClintock, a Latin professor at Hampden-\n",
      "\n",
      "Sydney College  in Virginia,  looked  up  one \n",
      "\n",
      "of  the  more  obscure  Latin  words, \n",
      "\n",
      "consectetur, from a Lorem Ipsum passage, \n",
      "\n",
      "and going through the cites of the word in \n",
      "\n",
      "classical  literature,  discovered  the \n",
      "\n",
      "undoubtable source. Lorem Ipsum comes \n",
      "\n",
      "from  sections  1.10.32  and  1.10.33  of  \"de \n",
      "\n",
      "Finibus  Bonorum  et  Malorum\"  (The \n",
      "\n",
      "Extremes  of  Good  and  Evil)  by  Cicero, \n",
      "\n",
      "written in 45 BC. This book is a treatise on \n",
      "\n",
      "the  theory  of  ethics,  very  popular  during \n",
      "\n",
      "the  Renaissance.  The  first  line  of  Lorem \n",
      "\n",
      "Ipsum,  \"Lorem  ipsum  dolor  sit  amet..\", \n",
      "\n",
      "comes from a line in section 1.10.32. \n",
      "\n",
      "The standard chunk of Lorem Ipsum used \n",
      "\n",
      "since  the  1500s  is  reproduced  below  for \n",
      "\n",
      "those  interested.  Sections  1.10.32  and \n",
      "\n",
      "1.10.33  from  \"de  Finibus  Bonorum  et \n",
      "\n",
      "Malorum\" by Cicero are also reproduced in \n",
      "\n",
      "their exact original form, accompanied by \n",
      "\n",
      "English versions from the 1914 translation \n",
      "\n",
      "by H. Rackham. \n",
      "\n",
      "Where can I get some? \n",
      "\n",
      "There are many variations of passages of \n",
      "\n",
      "Lorem  Ipsum  available,  but  the  majority \n",
      "\n",
      "have suffered alteration in some form, by \n",
      "\n",
      "injected  humour,  or  randomised  words \n"
     ]
    }
   ],
   "source": [
    "# The previous cell defines the function. This one actually runs it on the pre-defined directory\n",
    "\n",
    "convert_pdfs(files_to_iterate)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "invalid-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._reader.PdfFileReader object at 0x000001B7BCD43AC0>1\n",
      "<PyPDF2._reader.PdfFileReader object at 0x000001B7BCD450D0>2\n",
      "<PyPDF2._reader.PdfFileReader object at 0x000001B7BCD450D0>1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-wheel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
